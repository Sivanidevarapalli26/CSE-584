# -*- coding: utf-8 -*-
"""Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C2hDjAlPHODg2ixGlsXKjy06C-VF-LLi
"""

import pandas as pd

# Function to load xi and xj pairs from respective files
def load_xi_xj_pairs(xi_file_path, xj_file_path, label):
    with open(xi_file_path, 'r') as f_xi, open(xj_file_path, 'r') as f_xj:
        xi_sentences = [line.strip() for line in f_xi.readlines()]
        xj_sentences = [line.strip() for line in f_xj.readlines()]

    # Ensure both files have the same number of lines
    assert len(xi_sentences) == len(xj_sentences), "Mismatch in number of lines between xi and xj files."

    xi_xj_pairs = [(xi, xj, label) for xi, xj in zip(xi_sentences, xj_sentences)]
    return xi_xj_pairs

# Load data from all four LLMs
gpt2_pairs = load_xi_xj_pairs('/content/matched_truncated1.txt', '/content/gpt2_xj.txt', 'gpt-2')
gptneo_pairs = load_xi_xj_pairs('/content/matched_truncated1.txt', '/content/gptneo_xj.txt', 'gpt-neo')
falcon_pairs = load_xi_xj_pairs('/content/matched_truncated1.txt', '/content/falcon_xj.txt', 'falcon')
facebookopt_pairs = load_xi_xj_pairs('/content/matched_truncated1.txt', '/content/facebookopt_xj.txt', 'facebook-opt')

# Combine all data
all_pairs = gpt2_pairs + gptneo_pairs + falcon_pairs + facebookopt_pairs

# Create a DataFrame for easier handling
data = pd.DataFrame(all_pairs, columns=['xi', 'xj', 'label'])

# Map labels to numeric values
label_map = {'gpt-2': 0, 'gpt-neo': 1, 'falcon': 2, 'facebook-opt': 3}
data['label'] = data['label'].map(label_map)

# Print the prepared DataFrame
print(data.head(10))

from transformers import BertTokenizer, BertModel

# Initialize tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
bert_model = BertModel.from_pretrained('bert-base-uncased')

def get_embeddings(xi, xj):
    combined_text = xi + " [SEP] " + xj
    encoding = tokenizer(
        combined_text,
        return_tensors='pt',
        padding=True,
        truncation=True,
        max_length=128
    ).to(device)

    with torch.no_grad():
        outputs = bert_model(**encoding)
        last_hidden_state = outputs.last_hidden_state

        # Apply mean pooling to the last hidden state
        mean_pooled_output = torch.mean(last_hidden_state, dim=1)

    return mean_pooled_output

from sklearn.model_selection import train_test_split
import torch

# Assuming 'data' is your full DataFrame containing 'xi', 'xj', and 'label'
# Split the data into training and test sets (80% for training, 20% for testing)
train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)

# Check if the train_data and test_data are defined correctly
print(f"Training data shape: {train_data.shape}")
print(f"Test data shape: {test_data.shape}")

from torch.utils.data import DataLoader
import torch

def prepare_data(data, batch_size=32):
    combined_texts = [f"{row['xi']} [SEP] {row['xj']}" for _, row in data.iterrows()]
    labels = data['label'].values

    # Create a DataLoader to process data in batches
    # The DataLoader should iterate over combined_texts and labels separately
    data_loader = DataLoader(list(zip(combined_texts, labels)), batch_size=batch_size, shuffle=False)

    embeddings = []
    label_list = []

    # Determine the device (GPU or CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Set the model to evaluation mode and move it to the device
    bert_model.eval()
    bert_model.to(device)  # Move the model to the device
    # Set the model to evaluation mode
    bert_model.eval()
    with torch.no_grad():  # Disable gradient tracking for efficiency
        for batch in data_loader:
            # The batch now contains two elements: texts and batch_labels
            texts, batch_labels = batch

            # Tokenize the batch
            encoding = tokenizer(
                list(texts),
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=128
            ).to(device)  # Move to GPU if available

            # Get the pooled output from BERT
            outputs = bert_model(**encoding)
            pooled_output = outputs.pooler_output  # Shape: (batch_size, hidden_size)

            embeddings.append(pooled_output.cpu())  # Move to CPU to prevent GPU memory overload
            label_list.extend(batch_labels)

    # Concatenate all embeddings and convert labels to tensors
    return torch.cat(embeddings), torch.tensor(label_list)

# Prepare training and test data
train_embeddings, train_labels = prepare_data(train_data, batch_size=32)
test_embeddings, test_labels = prepare_data(test_data, batch_size=32)

import torch
from torch import nn

class LLMClassifier(nn.Module):
    def __init__(self, input_size, num_labels, dropout_rate=0.1):
        super(LLMClassifier, self).__init__()
        self.fc1 = nn.Linear(input_size, 512)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout_rate)  # Dropout after the first layer
        self.fc2 = nn.Linear(512, num_labels)  # Final output layer for classification

    def forward(self, concatenated_embeddings):
        x = self.fc1(concatenated_embeddings)
        x = self.relu(x)
        x = self.dropout(x)  # Apply dropout
        return self.fc2(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
hidden_size = 768  # BERT's hidden size
input_size = hidden_size  # Using pooled output size
num_labels = 4  # Number of LLMs

model = LLMClassifier(input_size=input_size, num_labels=num_labels)
model.to(device)  # Move the model to the appropriate device

from transformers import AdamW
from transformers import get_linear_schedule_with_warmup
import numpy as np

# Define optimizer, scheduler, and modified model
model = LLMClassifier(input_size=hidden_size, num_labels=num_labels).to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-2)  # Adding weight decay)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_embeddings) * 250)

from sklearn.utils.class_weight import compute_class_weight

class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels.numpy())
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)

# Use class weights in CrossEntropyLoss
loss_fn = nn.CrossEntropyLoss(weight=class_weights)

from sklearn.metrics import accuracy_score
# Modified training loop
def train_model(model, train_embeddings, train_labels, optimizer, scheduler, loss_fn, num_epochs=3):
    best_accuracy = 0.0
    patience = 10
    early_stop_counter = 0

    for epoch in range(num_epochs):
        model.train()
        optimizer.zero_grad()

        train_embeddings = train_embeddings.to(device)
        train_labels = train_labels.to(device)

        outputs = model(train_embeddings)
        loss = loss_fn(outputs, train_labels)

        loss.backward()
        optimizer.step()
        scheduler.step()

        # Evaluate on validation set
        model.eval()
        with torch.no_grad():
            val_outputs = model(test_embeddings.to(device))
            _, preds = torch.max(val_outputs, dim=1)
            val_accuracy = accuracy_score(test_labels.cpu(), preds.cpu())

        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}, Val Accuracy: {val_accuracy:.4f}')

        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            early_stop_counter = 0
            # Save the model checkpoint
            torch.save(model.state_dict(), 'best_model.pt')
        else:
            early_stop_counter += 1

        if early_stop_counter >= patience:
            print("Early stopping triggered.")
            break

train_model(model, train_embeddings, train_labels, optimizer, scheduler, loss_fn)

from sklearn.metrics import accuracy_score, classification_report

def evaluate_model(model, test_embeddings, test_labels):
    model.eval()  # Set the model to evaluation mode
    with torch.no_grad():  # Disable gradient tracking
        test_embeddings = test_embeddings.to(device)
        test_labels = test_labels.to(device)

        # Forward pass to get predictions
        outputs = model(test_embeddings)

        # Get the predicted class labels
        _, preds = torch.max(outputs, dim=1)

        # Calculate accuracy
        accuracy = accuracy_score(test_labels.cpu(), preds.cpu())
        print(f'Test Accuracy: {accuracy:.4f}')

        # Print classification report
        print(classification_report(test_labels.cpu(), preds.cpu(), target_names=['gpt-2', 'gpt-neo', 'falcon', 'facebook-opt']))

# Evaluate the model
evaluate_model(model, test_embeddings, test_labels)